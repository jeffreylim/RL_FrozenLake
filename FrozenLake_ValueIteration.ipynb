{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div class=\"alert alert-primary alert-info\">\n",
    "\n",
    "# Frozen Lake $4\\times4$ „Å® $8\\times8$\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "- ### Value-Iteration\n",
    "    \n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='frozenlake.jpg' width=1000 height=50/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-primary alert-info\">\n",
    "\n",
    "## Non-slippery version\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transitional probabilities are deterministic in the unslippery version. We can simplify\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "v_{\\pi}(s) &:= \\sup_{\\forall{a}} \\{ \\sum_{\\forall{s'}} p_{ss'}^a (R_{s'}^a + \\gamma v_{\\pi}(s')) \\} \\\\\n",
    "&=  \\sup_{\\forall{a}} \\{ R_{s'}^a + \\gamma v_{\\pi}(s') \\}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "Let $\\gamma$ be the discount factor. Terminate search if updates $\\lt \\epsilon(1-\\gamma) \\gamma^{-1}$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma, epsilon):\n",
    "\n",
    "    state_values = np.zeros(env.nS)\n",
    "    \n",
    "    def compute_state_value(curr_state):\n",
    "        best_state_value = 0.0\n",
    "        for action in range(env.nA):\n",
    "            transition_probability, next_state, reward, done = env.P[curr_state][action][0]\n",
    "            best_state_value = max(best_state_value, reward + gamma * state_values[next_state])\n",
    "        return best_state_value\n",
    "    \n",
    "    def print_state_values(n):\n",
    "        print('\\nState Values:')\n",
    "        idx = 0\n",
    "        for state, value in enumerate(state_values):\n",
    "            idx += 1\n",
    "            print(round(value, 4), end='\\t')\n",
    "            if idx % n is 0:\n",
    "                print()\n",
    "            if idx == env.nS - 1:\n",
    "                print('Goal')\n",
    "                break\n",
    "    \n",
    "    env.reset()\n",
    "    print('Start:')\n",
    "    env.render()\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        prev_state_values = state_values.copy()\n",
    "        iteration += 1\n",
    "        for state in range(env.nS - 1):\n",
    "            state_values[state] = compute_state_value(state)\n",
    "            delta = max(delta, np.fabs(prev_state_values[state] - state_values[state]))\n",
    "        if delta < epsilon * (1 - gamma) / gamma:\n",
    "            print('\\nNumber of Iterations: ', iteration)\n",
    "            print('Delta: ', delta)\n",
    "            if env.nS == 64:\n",
    "                print_state_values(8)\n",
    "            else:\n",
    "                print_state_values(4)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### $4\\times4$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Number of Iterations:  7\n",
      "Delta:  0\n",
      "\n",
      "State Values:\n",
      "0.995\t0.996\t0.997\t0.996\t\n",
      "0.996\t0.0\t0.998\t0.0\t\n",
      "0.997\t0.998\t0.999\t0.0\t\n",
      "0.0\t0.999\t1.0\tGoal\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0', is_slippery=False)\n",
    "gamma = 0.999\n",
    "epsilon = 0.01\n",
    "\n",
    "if __name__=='__main__':\n",
    "    value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### $8\\times8$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "\n",
      "Number of Iterations:  15\n",
      "Delta:  0\n",
      "\n",
      "State Values:\n",
      "0.9871\t0.9881\t0.9891\t0.99\t0.991\t0.992\t0.993\t0.994\t\n",
      "0.9881\t0.9891\t0.99\t0.991\t0.992\t0.993\t0.994\t0.995\t\n",
      "0.9891\t0.99\t0.991\t0.0\t0.993\t0.994\t0.995\t0.996\t\n",
      "0.99\t0.991\t0.992\t0.993\t0.994\t0.0\t0.996\t0.997\t\n",
      "0.9891\t0.99\t0.991\t0.0\t0.995\t0.996\t0.997\t0.998\t\n",
      "0.9881\t0.0\t0.0\t0.995\t0.996\t0.997\t0.0\t0.999\t\n",
      "0.9891\t0.0\t0.993\t0.994\t0.0\t0.998\t0.0\t1.0\t\n",
      "0.99\t0.991\t0.992\t0.0\t0.998\t0.999\t1.0\tGoal\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake8x8-v0', is_slippery=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div class=\"alert alert-primary alert-info\">\n",
    "\n",
    "## Slippery when Wet\n",
    "\n",
    "<img src='Slippery_when_wet.jpg' width=250 height=5/>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{align}\n",
    "v_{\\pi}(s) &:= \\sup_{\\forall{a}} \\{ \\sum_{\\forall{s'}} p_{ss'}^a (R_{s'}^a + \\gamma v_{\\pi}(s')) \\}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma, epsilon):\n",
    "\n",
    "    state_values = np.zeros(env.nS)\n",
    "    \n",
    "    def compute_state_value(curr_state):\n",
    "        best_state_value = 0.0\n",
    "        for action in range(env.nA):\n",
    "            total_expectation_state_value = 0.0\n",
    "            observations = env.P[curr_state][action]\n",
    "            for observation in observations:\n",
    "                transition_probability, next_state, reward, done = observation\n",
    "                total_expectation_state_value += ((reward + gamma * state_values[next_state]) * transition_probability)\n",
    "            best_state_value = max(best_state_value, total_expectation_state_value)\n",
    "        return best_state_value\n",
    "    \n",
    "    def print_state_values(n):\n",
    "        print('\\nState Values:')\n",
    "        idx = 0\n",
    "        for state, value in enumerate(state_values):\n",
    "            idx += 1\n",
    "            print(round(value, 4), end='\\t')\n",
    "            if idx % n is 0:\n",
    "                print()\n",
    "            if idx == env.nS - 1:\n",
    "                print('Goal')\n",
    "                break\n",
    "    \n",
    "    env.reset()\n",
    "    print('Start:')\n",
    "    env.render()\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        delta = 0\n",
    "        prev_state_values = state_values.copy()\n",
    "        iteration += 1\n",
    "        for state in range(env.nS - 1):\n",
    "            state_values[state] = compute_state_value(state)\n",
    "            delta = max(delta, np.fabs(prev_state_values[state] - state_values[state]))\n",
    "        if delta < epsilon * (1 - gamma) / gamma:\n",
    "            print('\\nNumber of Iterations: ', iteration)\n",
    "            print('Delta: ', delta)\n",
    "            if env.nS == 64:\n",
    "                print_state_values(8)\n",
    "            else:\n",
    "                print_state_values(4)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### $4\\times4$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Number of Iterations:  244\n",
      "Delta:  9.766677739331264e-06\n",
      "\n",
      "State Values:\n",
      "0.7854\t0.7783\t0.7737\t0.7713\t\n",
      "0.7877\t0.0\t0.5056\t0.0\t\n",
      "0.7925\t0.7996\t0.7447\t0.0\t\n",
      "0.0\t0.8641\t0.9311\tGoal\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0', is_slippery=True)\n",
    "gamma = 0.999\n",
    "epsilon = 0.01\n",
    "\n",
    "if __name__=='__main__':\n",
    "    value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### $8\\times8$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "\n",
      "Number of Iterations:  422\n",
      "Delta:  9.892355212981485e-06\n",
      "\n",
      "State Values:\n",
      "0.8925\t0.8952\t0.8992\t0.9038\t0.9087\t0.9137\t0.9185\t0.9223\t\n",
      "0.8919\t0.8939\t0.8973\t0.9016\t0.9064\t0.9116\t0.9175\t0.9251\t\n",
      "0.8764\t0.8621\t0.8187\t0.0\t0.7776\t0.8652\t0.909\t0.9306\t\n",
      "0.8636\t0.8113\t0.6991\t0.4205\t0.5636\t0.0\t0.8815\t0.939\t\n",
      "0.8534\t0.7107\t0.4695\t0.0\t0.4945\t0.5683\t0.7992\t0.9502\t\n",
      "0.8457\t0.0\t0.0\t0.1527\t0.353\t0.413\t0.0\t0.9642\t\n",
      "0.8406\t0.0\t0.1641\t0.1055\t0.0\t0.3188\t0.0\t0.9811\t\n",
      "0.8381\t0.6118\t0.3874\t0.0\t0.2718\t0.5443\t0.7715\tGoal\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake8x8-v0', is_slippery=True)\n",
    "gamma = 0.999\n",
    "epsilon = 0.01\n",
    "\n",
    "if __name__=='__main__':\n",
    "    value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
